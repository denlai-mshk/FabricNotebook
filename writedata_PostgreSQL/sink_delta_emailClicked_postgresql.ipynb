{"cells":[{"cell_type":"code","execution_count":27,"id":"f8c292f1-8a39-4463-9b0b-667b4f103308","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:39:46.6413843Z","execution_start_time":"2024-09-04T02:39:46.3832119Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"893c5f4c-a91b-4d26-b95a-24ff83bf1f11","queued_time":"2024-09-04T02:39:45.9032366Z","session_id":"800760f7-f1b5-4947-b676-c7db169eab19","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":29,"statement_ids":[29]},"text/plain":["StatementMeta(, 800760f7-f1b5-4947-b676-c7db169eab19, 29, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"}],"source":["\n","import os\n","#change to your service principle (Workspace identity) ClientID, tenantID and clientsecret\n","#customer should setup Azure Key Vault and store secret in AKV instead of hardcoding here\n","#https://www.datasarva.com/fabric-notebook-azurekeyvault/\n","AKV_ENDPOINT = \"https://xxx.vault.azure.net/\"\n","os.environ[\"AZURE_CLIENT_ID\"] = mssparkutils.credentials.getSecret(AKV_ENDPOINT, 'AZURE-CLIENT-ID')\n","os.environ[\"AZURE_TENANT_ID\"] = mssparkutils.credentials.getSecret(AKV_ENDPOINT, 'AZURE-TENANT-ID')\n","os.environ[\"AZURE_CLIENT_SECRET\"] = mssparkutils.credentials.getSecret(AKV_ENDPOINT, 'AZURE-CLIENT-SECRET')\n","#os.environ[\"AZURE_CLIENT_ID\"] = \"\"\n","#os.environ[\"AZURE_TENANT_ID\"] = \"\"\n","#os.environ[\"AZURE_CLIENT_SECRET\"] = \"\"\n","\n","#change to your workspace name\n","workspaceidty = \"IT-team-workspace\"\n","\n","#cut off date the data ingestion CIJ data, any record before this date will be ignored\n","cutoffdate = \"2024-05-09 09:46:55\""]},{"cell_type":"code","execution_count":28,"id":"88d29ff5-6f9e-4f7c-8d8c-6295273d153c","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:39:49.1106009Z","execution_start_time":"2024-09-04T02:39:48.2741919Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"5e619a58-ab56-44a6-88e7-7309c4da4dc2","queued_time":"2024-09-04T02:39:46.0218016Z","session_id":"800760f7-f1b5-4947-b676-c7db169eab19","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":30,"statement_ids":[30]},"text/plain":["StatementMeta(, 800760f7-f1b5-4947-b676-c7db169eab19, 30, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"}],"source":["from pyspark.sql import SparkSession\n","\n","from pyspark.sql.types import StructType, StructField, StringType\n","\n","# Initialize Spark session\n","spark = SparkSession.builder \\\n","    .appName(\"PostgreSQL Example\") \\\n","    .config(\"spark.jars\", \"/path/to/postgresql-42.2.18.jar\") \\\n","    .getOrCreate()\n","\n","# Define the JDBC URL and connection properties\n","jdbc_url = \"jdbc:postgresql://xxx.postgres.database.azure.com:5432/fabricoutput\"\n","\n","from azure.identity import DefaultAzureCredential\n","\n","credential = DefaultAzureCredential()\n","\n","token = credential.get_token(\"https://ossrdbms-aad.database.windows.net/.default\").token\n","\n","connection_properties = {\n","    \"user\": workspaceidty,\n","    \"password\": token,\n","    \"driver\": \"org.postgresql.Driver\"\n","}\n","\n","#print(\"token = \", token)"]},{"cell_type":"code","execution_count":53,"id":"f5289322-1569-403e-8def-5de83dabb4c9","metadata":{"editable":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}},"run_control":{"frozen":true}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:28:00.8594387Z","execution_start_time":"2024-09-04T02:28:00.0244333Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"37fd4e94-dc5d-4a81-b2a8-99de73ca9d53","queued_time":"2024-09-04T02:27:57.7601554Z","session_id":"5942b3cd-cfad-477e-aaca-bb96a1f003e1","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":55,"statement_ids":[55]},"text/plain":["StatementMeta(, 5942b3cd-cfad-477e-aaca-bb96a1f003e1, 55, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"}],"source":["# just for debug\n","schema = StructType([\n","    StructField(\"lasttimestamp\", StringType(), True)\n","])\n","\n","# Create the DataFrame\n","data = [(cutoffdate,)]\n","write_ts_df = spark.createDataFrame(data, schema)\n","\n","# Write DataFrame to PostgreSQL\n","write_ts_df.write \\\n","    .format(\"jdbc\") \\\n","    .option(\"url\", jdbc_url) \\\n","    .option(\"dbtable\", \"public.last_ts_clicked\") \\\n","    .options(**connection_properties) \\\n","    .mode(\"overwrite\") \\\n","    .save()"]},{"cell_type":"code","execution_count":29,"id":"e641ec50-639d-431b-8f69-98f734ff8738","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:39:50.4348585Z","execution_start_time":"2024-09-04T02:39:49.585885Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"87473886-ffbe-419f-aa76-1f2b36044356","queued_time":"2024-09-04T02:39:46.1898983Z","session_id":"800760f7-f1b5-4947-b676-c7db169eab19","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":31,"statement_ids":[31]},"text/plain":["StatementMeta(, 800760f7-f1b5-4947-b676-c7db169eab19, 31, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"}],"source":["# Load the Parquet files from the folder\n","df = spark.read.parquet(\"Files/EmailClicked\")\n","\n","# Show the DataFrame\n","#df.show()"]},{"cell_type":"code","execution_count":30,"id":"ea10930d-dda3-4fa0-b7b0-052cad9ceebf","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:39:51.1844637Z","execution_start_time":"2024-09-04T02:39:50.9183624Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"9c6a9bfe-0f0a-4f8f-b728-191d200ad4ef","queued_time":"2024-09-04T02:39:46.3406383Z","session_id":"800760f7-f1b5-4947-b676-c7db169eab19","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":32,"statement_ids":[32]},"text/plain":["StatementMeta(, 800760f7-f1b5-4947-b676-c7db169eab19, 32, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"}],"source":["# Show the schema of the DataFrame\n","# df.printSchema()"]},{"cell_type":"code","execution_count":31,"id":"f4369f1c-c035-4742-8331-5e329423ee7f","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:39:52.4676673Z","execution_start_time":"2024-09-04T02:39:51.6694389Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"a9f027c5-0c2a-457f-a84c-c69e9a2682e5","queued_time":"2024-09-04T02:39:46.5642861Z","session_id":"800760f7-f1b5-4947-b676-c7db169eab19","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":33,"statement_ids":[33]},"text/plain":["StatementMeta(, 800760f7-f1b5-4947-b676-c7db169eab19, 33, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["table_exists = NO\n","last_ts =  2024-05-09 09:46:55\n"]}],"source":["\n","# Query to check if the table exists\n","query = \"\"\"\n","SELECT EXISTS (\n","    SELECT 1\n","    FROM information_schema.tables \n","    WHERE table_schema = 'public'\n","    AND table_name = 'last_ts_clicked'\n",") AS table_exists\n","\"\"\"\n","\n","# Execute the query\n","dfchecktbl = spark.read \\\n","    .format(\"jdbc\") \\\n","    .option(\"url\", jdbc_url) \\\n","    .option(\"query\", query) \\\n","    .options(**connection_properties) \\\n","    .load()\n","\n","# Check if the table exists\n","table_exists = dfchecktbl.collect()[0][\"table_exists\"]\n","\n","if not table_exists:\n","    print(\"table_exists = NO\", )\n","    # Define the schema\n","    schema = StructType([\n","        StructField(\"lasttimestamp\", StringType(), True)\n","    ])\n","\n","    # Create the DataFrame\n","    data = [(cutoffdate,)]\n","    write_ts_df = spark.createDataFrame(data, schema)\n","\n","    # Write DataFrame to PostgreSQL\n","    write_ts_df.write \\\n","      .format(\"jdbc\") \\\n","      .option(\"url\", jdbc_url) \\\n","      .option(\"dbtable\", \"public.last_ts_clicked\") \\\n","      .options(**connection_properties) \\\n","      .mode(\"overwrite\") \\\n","      .save()\n","    \n","    last_ts = cutoffdate\n","    print(\"last_ts = \", last_ts)      \n","else:\n","    print(\"table_exists = YES\", )\n","    # Read the table\n","    load_ts_df = spark.read \\\n","        .format(\"jdbc\") \\\n","        .option(\"url\", jdbc_url) \\\n","        .option(\"dbtable\", \"public.last_ts_clicked\") \\\n","        .options(**connection_properties) \\\n","        .load()\n","\n","    # Show the first row value\n","    first_row = load_ts_df.first()\n","    last_ts = first_row[\"lasttimestamp\"]\n","    print(\"last_ts = \", last_ts)\n","    load_ts_df.show()"]},{"cell_type":"code","execution_count":32,"id":"f6cd7f58-3fde-4844-8b72-ce17464de0db","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:39:53.1537212Z","execution_start_time":"2024-09-04T02:39:52.893203Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"99c099a1-611e-4e3a-a4e8-f6cb63738c05","queued_time":"2024-09-04T02:39:46.7293103Z","session_id":"800760f7-f1b5-4947-b676-c7db169eab19","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":34,"statement_ids":[34]},"text/plain":["StatementMeta(, 800760f7-f1b5-4947-b676-c7db169eab19, 34, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"}],"source":["# Get a list of all column names\n","#columns = df.columns\n","#print(\"Columns: \", columns)\n","\n","# Rename columns\n","#df = df.withColumnRenamed(\"old_name1\", \"new_name1\")    \n","\n","# Select only the \"ActivityId\" and \"Timestamp\" columns\n","#selected_df = df.select(\"ActivityId\", \"Timestamp\")\n","\n","# Show the DataFrame with only the selected columns\n","#selected_df.show()"]},{"cell_type":"code","execution_count":33,"id":"f6fde865-ac79-41be-98d8-a3a06d279cfe","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:39:55.1681607Z","execution_start_time":"2024-09-04T02:39:53.5761395Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"51e87c85-5453-4cf3-89d6-6c6c9d142ff4","queued_time":"2024-09-04T02:39:46.8595737Z","session_id":"800760f7-f1b5-4947-b676-c7db169eab19","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":35,"statement_ids":[35]},"text/plain":["StatementMeta(, 800760f7-f1b5-4947-b676-c7db169eab19, 35, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["before dedup count =  5\n","after dedup count =  5\n","newlast_ts 2024-05-09 09:47:15\n"]}],"source":["from pyspark.sql.functions import col\n","\n","\n","# Sort the DataFrame by Timestamp in ascending order\n","sorted_df = df.orderBy(col(\"Timestamp\").asc())\n","\n","# Filter the DataFrame to include only records with Timestamp > '2024-05-09 09:46:55'\n","dupfiltered_df = sorted_df.filter(col(\"Timestamp\") > last_ts)\n","\n","# Deduplicate the DataFrame\n","print(\"before dedup count = \", dupfiltered_df.count())\n","filtered_df = dupfiltered_df.dropDuplicates()\n","print(\"after dedup count = \", filtered_df.count())\n","\n","# Get the last record's Timestamp\n","newlast_ts = filtered_df.collect()[-1]['Timestamp']\n","\n","if not isinstance(newlast_ts, str):\n","    newlast_ts = str(newlast_ts)\n","\n","print(\"newlast_ts\", newlast_ts)\n","\n","# Show the filtered DataFrame\n","#filtered_df.show()"]},{"cell_type":"code","execution_count":34,"id":"3f1b6f93-fdef-41a1-b48c-acbe0efff89b","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:39:56.3759014Z","execution_start_time":"2024-09-04T02:39:55.5846706Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"6c9549e4-30ba-4148-95ec-633f792cc983","queued_time":"2024-09-04T02:39:46.9915417Z","session_id":"800760f7-f1b5-4947-b676-c7db169eab19","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":36,"statement_ids":[36]},"text/plain":["StatementMeta(, 800760f7-f1b5-4947-b676-c7db169eab19, 36, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Number of records: 5\n"]}],"source":["# Count the number of records in the filtered DataFrame\n","filtered_record_count = filtered_df.count()\n","\n","# Print the count\n","print(\"Number of records:\", filtered_record_count)"]},{"cell_type":"code","execution_count":35,"id":"48c11d90-3b7f-41e0-b73c-833108a6af90","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:39:57.6340086Z","execution_start_time":"2024-09-04T02:39:56.8199788Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"46f5e30e-a871-4f69-9e13-f011d4187236","queued_time":"2024-09-04T02:39:47.1613331Z","session_id":"800760f7-f1b5-4947-b676-c7db169eab19","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":37,"statement_ids":[37]},"text/plain":["StatementMeta(, 800760f7-f1b5-4947-b676-c7db169eab19, 37, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Number of records: 6\n"]}],"source":["# Count the number of records in the filtered DataFrame\n","record_count = df.count()\n","\n","# Print the count\n","print(\"Number of records:\", record_count)"]},{"cell_type":"code","execution_count":36,"id":"fb4f5f21-758e-49ed-8421-7497a4f2988f","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:39:58.9380493Z","execution_start_time":"2024-09-04T02:39:58.1185157Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"8e048f5b-42cd-4a8c-ae66-ca64158e7a92","queued_time":"2024-09-04T02:39:47.3022481Z","session_id":"800760f7-f1b5-4947-b676-c7db169eab19","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":38,"statement_ids":[38]},"text/plain":["StatementMeta(, 800760f7-f1b5-4947-b676-c7db169eab19, 38, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"}],"source":["# Write DataFrame to PostgreSQL\n","filtered_df.write \\\n","  .format(\"jdbc\") \\\n","  .option(\"url\", jdbc_url) \\\n","  .option(\"dbtable\", \"public.emailclicked\") \\\n","  .options(**connection_properties) \\\n","  .mode(\"append\") \\\n","  .save()\n"]},{"cell_type":"code","execution_count":37,"id":"70a5366e-58b1-4b7b-9f57-0995e30f195b","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:40:00.2146946Z","execution_start_time":"2024-09-04T02:39:59.3837091Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"e66d2859-00ff-4158-91f7-49eeeb2a983d","queued_time":"2024-09-04T02:39:47.5985649Z","session_id":"800760f7-f1b5-4947-b676-c7db169eab19","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":39,"statement_ids":[39]},"text/plain":["StatementMeta(, 800760f7-f1b5-4947-b676-c7db169eab19, 39, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Validation successful: The number of records matches.\n"]}],"source":["# just for debug\n","# Validate the records in db\n","# Read the table back from PostgreSQL\n","read_updated_df = spark.read \\\n","    .format(\"jdbc\") \\\n","    .option(\"url\", jdbc_url) \\\n","    .option(\"dbtable\", \"public.emailclicked\") \\\n","    .options(**connection_properties) \\\n","    .load()\n","\n","# Get the count of records in the original DataFrame\n","original_count = filtered_df.count()\n","\n","# Get the count of records in the table read from PostgreSQL\n","added_count = read_updated_df.count()\n","\n","# Validate the counts\n","if original_count == added_count:\n","    print(\"Validation successful: The number of records matches.\")\n","else:\n","    print(f\"Validation failed: Original count = {original_count}, added_count = {added_count}\")"]},{"cell_type":"code","execution_count":38,"id":"47c7353d-ce0a-427a-9371-7f18f5b3b1ce","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:40:01.947021Z","execution_start_time":"2024-09-04T02:40:00.6753559Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"6c26cf41-2ca0-47dc-b55a-7d8ce1e6a268","queued_time":"2024-09-04T02:39:48.5639683Z","session_id":"800760f7-f1b5-4947-b676-c7db169eab19","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":40,"statement_ids":[40]},"text/plain":["StatementMeta(, 800760f7-f1b5-4947-b676-c7db169eab19, 40, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["newlast_ts 2024-05-09 09:47:15\n"]}],"source":["# Write new timestamp \n","\n","schema = StructType([\n","    StructField(\"lasttimestamp\", StringType(), True)\n","])\n","print(\"newlast_ts\", newlast_ts)\n","data = [(newlast_ts,)]\n","newts_df = spark.createDataFrame(data, schema)\n","\n","\n","newts_df.write \\\n","    .format(\"jdbc\") \\\n","    .option(\"url\", jdbc_url) \\\n","    .option(\"dbtable\", \"public.last_ts_clicked\") \\\n","    .options(**connection_properties) \\\n","    .mode(\"overwrite\") \\\n","    .save()\n","\n"]},{"cell_type":"code","execution_count":39,"id":"da934144-3688-4f59-814e-f0621d64b79f","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:40:03.2008116Z","execution_start_time":"2024-09-04T02:40:02.3725429Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"095c8eb3-3349-45f7-9329-d5211a44c5a2","queued_time":"2024-09-04T02:39:48.918306Z","session_id":"800760f7-f1b5-4947-b676-c7db169eab19","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":41,"statement_ids":[41]},"text/plain":["StatementMeta(, 800760f7-f1b5-4947-b676-c7db169eab19, 41, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["newlast_ts =  2024-05-09 09:47:15\n"]}],"source":["# just for debug\n","# Validate the timestamp records in db\n","read_ts_df = spark.read \\\n","    .format(\"jdbc\") \\\n","    .option(\"url\", jdbc_url) \\\n","    .option(\"dbtable\", \"last_ts_clicked\") \\\n","    .options(**connection_properties) \\\n","    .load()\n","\n","\n","# Show the first row value\n","first_row = read_ts_df.first()\n","newlast_ts = first_row[\"lasttimestamp\"]\n","print(\"newlast_ts = \", newlast_ts)\n"]}],"metadata":{"dependencies":{"lakehouse":{"default_lakehouse":"bdc8380d-da0d-48f4-b4e3-12e3dcd8740d","default_lakehouse_name":"d365dataverse","default_lakehouse_workspace_id":"0aa7885d-6ff7-45d8-93e8-81e61bc457f2"}},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Synapse PySpark","language":"Python","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"widgets":{}},"nbformat":4,"nbformat_minor":5}
