{"cells":[{"cell_type":"code","execution_count":1,"id":"f8c292f1-8a39-4463-9b0b-667b4f103308","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:31:35.0804293Z","execution_start_time":"2024-09-04T02:31:32.4672961Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"96d68668-cf48-45ff-a01c-28c0dbb299fa","queued_time":"2024-09-04T02:31:27.1404537Z","session_id":"425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":3,"statement_ids":[3]},"text/plain":["StatementMeta(, 425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e, 3, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"}],"source":["\n","import os\n","#change to your service principle (Workspace identity) ClientID, tenantID and clientsecret\n","#customer should setup Azure Key Vault and store secret in AKV instead of hardcoding here\n","#https://www.datasarva.com/fabric-notebook-azurekeyvault/\n","AKV_ENDPOINT = \"https://xxx.vault.azure.net/\"\n","os.environ[\"AZURE_CLIENT_ID\"] = mssparkutils.credentials.getSecret(AKV_ENDPOINT, 'AZURE-CLIENT-ID')\n","os.environ[\"AZURE_TENANT_ID\"] = mssparkutils.credentials.getSecret(AKV_ENDPOINT, 'AZURE-TENANT-ID')\n","os.environ[\"AZURE_CLIENT_SECRET\"] = mssparkutils.credentials.getSecret(AKV_ENDPOINT, 'AZURE-CLIENT-SECRET')\n","#os.environ[\"AZURE_CLIENT_ID\"] = \"\"\n","#os.environ[\"AZURE_TENANT_ID\"] = \"\"\n","#os.environ[\"AZURE_CLIENT_SECRET\"] = \"\"\n","\n","#change to your workspace name\n","workspaceidty = \"IT-team-workspace\"\n","\n","#cut off date the data ingestion CIJ data, any record before this date will be ignored\n","cutoffdate = \"2024-05-09 09:46:55\""]},{"cell_type":"code","execution_count":2,"id":"88d29ff5-6f9e-4f7c-8d8c-6295273d153c","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:31:36.7068527Z","execution_start_time":"2024-09-04T02:31:35.5235303Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"036d3899-f9ea-46b5-b956-8ca5810e5887","queued_time":"2024-09-04T02:31:27.2572392Z","session_id":"425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":4,"statement_ids":[4]},"text/plain":["StatementMeta(, 425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e, 4, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"}],"source":["from pyspark.sql import SparkSession\n","\n","from pyspark.sql.types import StructType, StructField, StringType\n","\n","# Initialize Spark session\n","spark = SparkSession.builder \\\n","    .appName(\"PostgreSQL Example\") \\\n","    .config(\"spark.jars\", \"/path/to/postgresql-42.2.18.jar\") \\\n","    .getOrCreate()\n","\n","# Define the JDBC URL and connection properties\n","jdbc_url = \"jdbc:postgresql://xxx.postgres.database.azure.com:5432/fabricoutput\"\n","\n","from azure.identity import DefaultAzureCredential\n","\n","credential = DefaultAzureCredential()\n","\n","token = credential.get_token(\"https://ossrdbms-aad.database.windows.net/.default\").token\n","\n","connection_properties = {\n","    \"user\": workspaceidty,\n","    \"password\": token,\n","    \"driver\": \"org.postgresql.Driver\"\n","}\n","\n","#print(\"token = \", token)"]},{"cell_type":"code","execution_count":6,"id":"f5289322-1569-403e-8def-5de83dabb4c9","metadata":{"editable":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}},"run_control":{"frozen":true}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-03T13:49:34.8666667Z","execution_start_time":"2024-09-03T13:49:26.6851237Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"9354b8dd-8fca-4231-a9d5-ed622356bf5f","queued_time":"2024-09-03T13:49:26.2862256Z","session_id":"b9cb0934-2102-47d6-9bbd-7f6942b8ed1e","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":8,"statement_ids":[8]},"text/plain":["StatementMeta(, b9cb0934-2102-47d6-9bbd-7f6942b8ed1e, 8, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"}],"source":["# just for debug\n","schema = StructType([\n","    StructField(\"lasttimestamp\", StringType(), True)\n","])\n","\n","# Create the DataFrame\n","data = [(cutoffdate,)]\n","write_ts_df = spark.createDataFrame(data, schema)\n","\n","# Write DataFrame to PostgreSQL\n","write_ts_df.write \\\n","    .format(\"jdbc\") \\\n","    .option(\"url\", jdbc_url) \\\n","    .option(\"dbtable\", \"public.last_ts_opened\") \\\n","    .options(**connection_properties) \\\n","    .mode(\"overwrite\") \\\n","    .save()"]},{"cell_type":"code","execution_count":3,"id":"e641ec50-639d-431b-8f69-98f734ff8738","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:31:43.6684073Z","execution_start_time":"2024-09-04T02:31:37.150321Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"c45fdd62-58e1-42e2-a410-7f372c0c5233","queued_time":"2024-09-04T02:31:27.3637052Z","session_id":"425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":5,"statement_ids":[5]},"text/plain":["StatementMeta(, 425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e, 5, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"}],"source":["# Load the Parquet files from the folder\n","df = spark.read.parquet(\"Files/EmailOpened\")\n","\n","# Show the DataFrame\n","#df.show()"]},{"cell_type":"code","execution_count":4,"id":"ea10930d-dda3-4fa0-b7b0-052cad9ceebf","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:31:44.3438487Z","execution_start_time":"2024-09-04T02:31:44.0799716Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"abf841f7-72a7-46da-a982-ac3fdc39bea6","queued_time":"2024-09-04T02:31:27.4965141Z","session_id":"425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":6,"statement_ids":[6]},"text/plain":["StatementMeta(, 425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e, 6, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"}],"source":["# Show the schema of the DataFrame\n","# df.printSchema()"]},{"cell_type":"code","execution_count":5,"id":"f4369f1c-c035-4742-8331-5e329423ee7f","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:31:51.2541667Z","execution_start_time":"2024-09-04T02:31:44.7781689Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"d43e5975-1260-4cf5-8092-352de701fe9b","queued_time":"2024-09-04T02:31:27.663695Z","session_id":"425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":7,"statement_ids":[7]},"text/plain":["StatementMeta(, 425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e, 7, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["table_exists = NO\n","last_ts =  2024-05-09 09:46:55\n"]}],"source":["\n","# Query to check if the table exists\n","query = \"\"\"\n","SELECT EXISTS (\n","    SELECT 1\n","    FROM information_schema.tables \n","    WHERE table_schema = 'public'\n","    AND table_name = 'last_ts_opened'\n",") AS table_exists\n","\"\"\"\n","\n","# Execute the query\n","dfchecktbl = spark.read \\\n","    .format(\"jdbc\") \\\n","    .option(\"url\", jdbc_url) \\\n","    .option(\"query\", query) \\\n","    .options(**connection_properties) \\\n","    .load()\n","\n","# Check if the table exists\n","table_exists = dfchecktbl.collect()[0][\"table_exists\"]\n","\n","if not table_exists:\n","    print(\"table_exists = NO\", )\n","    # Define the schema\n","    schema = StructType([\n","        StructField(\"lasttimestamp\", StringType(), True)\n","    ])\n","\n","    # Create the DataFrame\n","    data = [(cutoffdate,)]\n","    write_ts_df = spark.createDataFrame(data, schema)\n","\n","    # Write DataFrame to PostgreSQL\n","    write_ts_df.write \\\n","      .format(\"jdbc\") \\\n","      .option(\"url\", jdbc_url) \\\n","      .option(\"dbtable\", \"public.last_ts_opened\") \\\n","      .options(**connection_properties) \\\n","      .mode(\"overwrite\") \\\n","      .save()\n","\n","    last_ts = cutoffdate\n","    print(\"last_ts = \", last_ts)\n","else:\n","    print(\"table_exists = YES\", )\n","    # Read the table\n","    load_ts_df = spark.read \\\n","        .format(\"jdbc\") \\\n","        .option(\"url\", jdbc_url) \\\n","        .option(\"dbtable\", \"public.last_ts_opened\") \\\n","        .options(**connection_properties) \\\n","        .load()\n","\n","    # Show the first row value\n","    first_row = load_ts_df.first()\n","    last_ts = first_row[\"lasttimestamp\"]\n","    print(\"last_ts = \", last_ts)\n","    load_ts_df.show()"]},{"cell_type":"code","execution_count":6,"id":"f6cd7f58-3fde-4844-8b72-ce17464de0db","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:31:51.8872709Z","execution_start_time":"2024-09-04T02:31:51.6430343Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"39e12ae0-7d92-4a70-ab39-32bc88a69a9f","queued_time":"2024-09-04T02:31:27.8405442Z","session_id":"425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":8,"statement_ids":[8]},"text/plain":["StatementMeta(, 425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e, 8, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"}],"source":["# Get a list of all column names\n","#columns = df.columns\n","#print(\"Columns: \", columns)\n","\n","# Rename columns\n","#df = df.withColumnRenamed(\"old_name1\", \"new_name1\")    \n","\n","# Select only the \"ActivityId\" and \"Timestamp\" columns\n","#selected_df = df.select(\"ActivityId\", \"Timestamp\")\n","\n","# Show the DataFrame with only the selected columns\n","#selected_df.show()"]},{"cell_type":"code","execution_count":7,"id":"f6fde865-ac79-41be-98d8-a3a06d279cfe","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:31:57.2139501Z","execution_start_time":"2024-09-04T02:31:52.291523Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"aca1bd5d-ee6c-4e21-8562-8715c438c2d2","queued_time":"2024-09-04T02:31:27.9929379Z","session_id":"425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":9,"statement_ids":[9]},"text/plain":["StatementMeta(, 425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e, 9, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["before dedup count =  18\n","after dedup count =  9\n","newlast_ts 2024-05-12 10:23:40\n"]}],"source":["from pyspark.sql.functions import col\n","\n","\n","# Sort the DataFrame by Timestamp in ascending order\n","sorted_df = df.orderBy(col(\"Timestamp\").asc())\n","\n","# Filter the DataFrame to include only records with Timestamp > '2024-05-09 09:46:55'\n","dupfiltered_df = sorted_df.filter(col(\"Timestamp\") > last_ts)\n","\n","# Deduplicate the DataFrame\n","print(\"before dedup count = \", dupfiltered_df.count())\n","filtered_df = dupfiltered_df.dropDuplicates()\n","print(\"after dedup count = \", filtered_df.count())\n","\n","# Get the last record's Timestamp\n","newlast_ts = filtered_df.collect()[-1]['Timestamp']\n","\n","if not isinstance(newlast_ts, str):\n","    newlast_ts = str(newlast_ts)\n","\n","print(\"newlast_ts\", newlast_ts)\n","\n","# Show the filtered DataFrame\n","#filtered_df.show()"]},{"cell_type":"code","execution_count":8,"id":"3f1b6f93-fdef-41a1-b48c-acbe0efff89b","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:31:58.4525064Z","execution_start_time":"2024-09-04T02:31:57.6269693Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"337753e6-90d9-4c39-bd44-058b0f977e90","queued_time":"2024-09-04T02:31:28.2280839Z","session_id":"425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":10,"statement_ids":[10]},"text/plain":["StatementMeta(, 425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e, 10, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Number of records: 9\n"]}],"source":["# Count the number of records in the filtered DataFrame\n","filtered_record_count = filtered_df.count()\n","\n","# Print the count\n","print(\"Number of records:\", filtered_record_count)"]},{"cell_type":"code","execution_count":9,"id":"48c11d90-3b7f-41e0-b73c-833108a6af90","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:31:59.6246283Z","execution_start_time":"2024-09-04T02:31:58.8422227Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"cc29a0f3-cc64-428f-bfaf-1a36ae54eb4d","queued_time":"2024-09-04T02:31:28.4040182Z","session_id":"425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":11,"statement_ids":[11]},"text/plain":["StatementMeta(, 425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e, 11, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Number of records: 36\n"]}],"source":["# Count the number of records in the filtered DataFrame\n","record_count = df.count()\n","\n","# Print the count\n","print(\"Number of records:\", record_count)"]},{"cell_type":"code","execution_count":10,"id":"fb4f5f21-758e-49ed-8421-7497a4f2988f","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:32:01.6256494Z","execution_start_time":"2024-09-04T02:32:00.0494834Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"8ffae11c-19f6-4abe-8f50-03b6eb8da061","queued_time":"2024-09-04T02:31:28.5902927Z","session_id":"425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":12,"statement_ids":[12]},"text/plain":["StatementMeta(, 425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e, 12, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"}],"source":["# Write DataFrame to PostgreSQL\n","filtered_df.write \\\n","  .format(\"jdbc\") \\\n","  .option(\"url\", jdbc_url) \\\n","  .option(\"dbtable\", \"public.emailopened\") \\\n","  .options(**connection_properties) \\\n","  .mode(\"append\") \\\n","  .save()\n"]},{"cell_type":"code","execution_count":11,"id":"70a5366e-58b1-4b7b-9f57-0995e30f195b","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:32:03.582554Z","execution_start_time":"2024-09-04T02:32:02.0553593Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"0337e1b4-e968-4ccf-9047-592dfb14dddb","queued_time":"2024-09-04T02:31:28.7544752Z","session_id":"425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":13,"statement_ids":[13]},"text/plain":["StatementMeta(, 425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e, 13, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Validation successful: The number of records matches.\n"]}],"source":["# just for debug\n","# Validate the records in db\n","# Read the table back from PostgreSQL\n","read_updated_df = spark.read \\\n","    .format(\"jdbc\") \\\n","    .option(\"url\", jdbc_url) \\\n","    .option(\"dbtable\", \"public.emailopened\") \\\n","    .options(**connection_properties) \\\n","    .load()\n","\n","# Get the count of records in the original DataFrame\n","original_count = filtered_df.count()\n","\n","# Get the count of records in the table read from PostgreSQL\n","added_count = read_updated_df.count()\n","\n","# Validate the counts\n","if original_count == added_count:\n","    print(\"Validation successful: The number of records matches.\")\n","else:\n","    print(f\"Validation failed: Original count = {original_count}, added_count = {added_count}\")"]},{"cell_type":"code","execution_count":12,"id":"47c7353d-ce0a-427a-9371-7f18f5b3b1ce","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:32:04.8478223Z","execution_start_time":"2024-09-04T02:32:03.9934809Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"13141663-b161-4bb5-b5ac-463bad2405da","queued_time":"2024-09-04T02:31:28.923185Z","session_id":"425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":14,"statement_ids":[14]},"text/plain":["StatementMeta(, 425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e, 14, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["newlast_ts 2024-05-12 10:23:40\n"]}],"source":["# Write new timestamp \n","\n","schema = StructType([\n","    StructField(\"lasttimestamp\", StringType(), True)\n","])\n","print(\"newlast_ts\", newlast_ts)\n","data = [(newlast_ts,)]\n","newts_df = spark.createDataFrame(data, schema)\n","\n","\n","newts_df.write \\\n","    .format(\"jdbc\") \\\n","    .option(\"url\", jdbc_url) \\\n","    .option(\"dbtable\", \"public.last_ts_opened\") \\\n","    .options(**connection_properties) \\\n","    .mode(\"overwrite\") \\\n","    .save()\n","\n"]},{"cell_type":"code","execution_count":13,"id":"da934144-3688-4f59-814e-f0621d64b79f","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2024-09-04T02:32:06.134813Z","execution_start_time":"2024-09-04T02:32:05.2822232Z","livy_statement_state":"available","normalized_state":"finished","parent_msg_id":"68b3526f-3e98-4ceb-8876-04aa3e04f6d4","queued_time":"2024-09-04T02:31:29.0668296Z","session_id":"425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e","session_start_time":null,"spark_pool":null,"state":"finished","statement_id":15,"statement_ids":[15]},"text/plain":["StatementMeta(, 425f4ecb-eb2b-45a2-9c48-d17dfbf04d4e, 15, Finished, Available, Finished)"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["newlast_ts =  2024-05-12 10:23:40\n"]}],"source":["# just for debug\n","# Validate the timestamp records in db\n","read_ts_df = spark.read \\\n","    .format(\"jdbc\") \\\n","    .option(\"url\", jdbc_url) \\\n","    .option(\"dbtable\", \"public.last_ts_opened\") \\\n","    .options(**connection_properties) \\\n","    .load()\n","\n","\n","# Show the first row value\n","first_row = read_ts_df.first()\n","newlast_ts = first_row[\"lasttimestamp\"]\n","print(\"newlast_ts = \", newlast_ts)\n"]}],"metadata":{"dependencies":{"lakehouse":{"default_lakehouse":"bdc8380d-da0d-48f4-b4e3-12e3dcd8740d","default_lakehouse_name":"d365dataverse","default_lakehouse_workspace_id":"0aa7885d-6ff7-45d8-93e8-81e61bc457f2"}},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Synapse PySpark","language":"Python","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"widgets":{}},"nbformat":4,"nbformat_minor":5}
